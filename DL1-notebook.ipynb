{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEEP LEARNING: PROJECT 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNCOMMENT YOUR PATH WHEN RUNNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COLE\n",
    "#os.chdir(\"C:\\\\Users\\\\cole\\\\Documents\\\\Spring MSBA\")\n",
    "\n",
    "#NOAH\n",
    "os.chdir(\"/Users/noahchu/Desktop/BZAN 554/project1/deep_learning_1\")\n",
    "\n",
    "#JAKE \n",
    "\n",
    "\n",
    "#KEVIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "READING IN DATA & PARSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "\n",
    "titles=[]\n",
    "categories=[]\n",
    "i = 0\n",
    "\n",
    "\n",
    "for d in parse('meta_Clothing_Shoes_and_Jewelry.json.gz'):\n",
    "    i += 1\n",
    "    X = (d['title'])\n",
    "    titles.append(X)\n",
    "    Y = np.array(d['category'])\n",
    "    categories.append(Y)\n",
    "    if i == 100:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TOKENIZING THE WORDS OF EACH TITLE AND REMOVING PUNCTUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "tokenized_sents = [tokenizer.tokenize(i) for i in titles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GETTING RID OF DUPLICATE WORDS IN TITLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_titles= []\n",
    "for sentence in tokenized_sents:\n",
    "    for word in sentence:\n",
    "        if word not in unique_titles:\n",
    "            unique_titles.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(unique_titles)\n",
    "vectorizer.vocabulary_\n",
    "X=vectorizer.transform(titles)\n",
    "Hotcoded_X = pd.DataFrame(X.toarray(),columns=vectorizer.get_feature_names())\n",
    "Hotcoded_X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING TO MAKE SURE NO DUPLICATE COLUMNS. IT CHECKS OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = Hotcoded_X.loc[:,~Hotcoded_X.columns.duplicated()]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING THAT ROWS 1 IN THE COLUMNS ADD UP TO THE AMOUNT OF WORDS IN THE TITLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hotcoded_X.iloc[99].sum()\n",
    "titles[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES FROM OFFICE HOURS \n",
    "\n",
    "feed in X variables 1 by 1. single row is 1X50000. Make list of unique cats, 10000. matrix is nx10000. set value to 1 where corresponding cat.\n",
    "#50000 x 100000 y every x is 1 except for where the column corresponds to the word in the title. \n",
    "For category not looking at words, looking at entire category.\n",
    "\n",
    "We will need a for loop for our model to retrieve the unique words from the titles.\n",
    "Each column is an entire category.\n",
    "The matrix will have 0s and 1sâ€¦ 1s will be the unique words in the title.\n",
    "How we tuned the model.\n",
    "How many layers and nodes.\n",
    "What activation function we tried.\n",
    "Challenges that came up from the project.\n",
    "More emphasis on the model rather the preparation.\n",
    "90% of the model, 10% data preparation (opposite of 545).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BAG OF WORDS CREATION FOR CATEGORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
